{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cyBERT: a flexible log parser based on the BERT language model\n",
    "\n",
    "## Table of Contents\n",
    "* Introduction\n",
    "* Generating Labeled Logs\n",
    "* Subword Tokenization\n",
    "* Data Loading\n",
    "* Fine-tuning pretrained BERT\n",
    "* Model Evaluation\n",
    "* Parsing with cyBERT\n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the most arduous tasks of any security operation (and equally as time consuming for a data scientist) is ETL and parsing. This notebook illustrates how to train a BERT language model using a toy dataset of just 1000 previously parsed apache server logs as a labeled data. We will fine-tune a pretrained BERT model from [HuggingFace](https://github.com/huggingface) with a classification layer for Named Entity Recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import s3fs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "from transformers import BertForTokenClassification\n",
    "from tqdm import tqdm,trange\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Labels For Our Training Dataset\n",
    "\n",
    "To train our model we begin with a dataframe containing parsed logs and additional `raw` column containing the whole raw log as a string. We will use the column names as our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download log data\n",
    "APACHE_SAMPLE_CSV = \"apache_sample_1k.csv\"\n",
    "S3_BASE_PATH = \"rapidsai-data/cyber/clx\"\n",
    "\n",
    "if not path.exists(APACHE_SAMPLE_CSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + APACHE_SAMPLE_CSV, APACHE_SAMPLE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = cudf.read_csv(APACHE_SAMPLE_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_level</th>\n",
       "      <th>error_message</th>\n",
       "      <th>raw</th>\n",
       "      <th>remote_host</th>\n",
       "      <th>remote_logname</th>\n",
       "      <th>remote_user</th>\n",
       "      <th>request_header_referer</th>\n",
       "      <th>request_header_user_agent</th>\n",
       "      <th>request_header_user_agent__browser__family</th>\n",
       "      <th>request_header_user_agent__browser__version_string</th>\n",
       "      <th>...</th>\n",
       "      <th>request_url_username</th>\n",
       "      <th>response_bytes_clf</th>\n",
       "      <th>status</th>\n",
       "      <th>time_received</th>\n",
       "      <th>time_received_datetimeobj</th>\n",
       "      <th>time_received_isoformat</th>\n",
       "      <th>time_received_tz_datetimeobj</th>\n",
       "      <th>time_received_tz_isoformat</th>\n",
       "      <th>time_received_utc_datetimeobj</th>\n",
       "      <th>time_received_utc_isoformat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>46.105.57.86 - - [21/Oct/2018:16:52:55 +0200] ...</td>\n",
       "      <td>46.105.57.86</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>http://almhuette-raith.at/administrator/index....</td>\n",
       "      <td>Mozilla/5.0 (Linux; U; Android 2.2) AppleWebKi...</td>\n",
       "      <td>Android</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4494</td>\n",
       "      <td>200.0</td>\n",
       "      <td>[21/Oct/2018:16:52:55 +0200]</td>\n",
       "      <td>1.540141e+12</td>\n",
       "      <td>2018-10-21T16:52:55</td>\n",
       "      <td>1.540134e+12</td>\n",
       "      <td>2018-10-21T16:52:55+02:00</td>\n",
       "      <td>1.540134e+12</td>\n",
       "      <td>2018-10-21T14:52:55+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    error_level error_message  \\\n",
       "829        <NA>          <NA>   \n",
       "\n",
       "                                                   raw   remote_host  \\\n",
       "829  46.105.57.86 - - [21/Oct/2018:16:52:55 +0200] ...  46.105.57.86   \n",
       "\n",
       "    remote_logname remote_user  \\\n",
       "829              -           -   \n",
       "\n",
       "                                request_header_referer  \\\n",
       "829  http://almhuette-raith.at/administrator/index....   \n",
       "\n",
       "                             request_header_user_agent  \\\n",
       "829  Mozilla/5.0 (Linux; U; Android 2.2) AppleWebKi...   \n",
       "\n",
       "    request_header_user_agent__browser__family  \\\n",
       "829                                    Android   \n",
       "\n",
       "    request_header_user_agent__browser__version_string  ...  \\\n",
       "829                                                2.2  ...   \n",
       "\n",
       "     request_url_username response_bytes_clf status  \\\n",
       "829                  <NA>               4494  200.0   \n",
       "\n",
       "                    time_received time_received_datetimeobj  \\\n",
       "829  [21/Oct/2018:16:52:55 +0200]              1.540141e+12   \n",
       "\n",
       "     time_received_isoformat time_received_tz_datetimeobj  \\\n",
       "829      2018-10-21T16:52:55                 1.540134e+12   \n",
       "\n",
       "     time_received_tz_isoformat time_received_utc_datetimeobj  \\\n",
       "829   2018-10-21T16:52:55+02:00                  1.540134e+12   \n",
       "\n",
       "     time_received_utc_isoformat  \n",
       "829    2018-10-21T14:52:55+00:00  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample parsed log\n",
    "logs_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.108.213.19 - - [18/Jul/2018:21:53:07 +0200] \"GET / HTTP/1.1\" 200 10439 \"-\" \"Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots)\" \"-\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample raw log\n",
    "print(logs_df.raw.loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeler(index_no, cols):\n",
    "    \"\"\"\n",
    "    label the words in the raw log with the column name from the parsed log\n",
    "    \"\"\"\n",
    "    raw_split = logs_df.raw_preprocess[index_no].split()\n",
    "    \n",
    "    # words in raw but not in parsed logs labeled as 'other'\n",
    "    label_list = ['O'] * len(raw_split) \n",
    "    \n",
    "    # for each parsed column find the location of the sequence of words (sublist) in the raw log\n",
    "    for col in cols:\n",
    "        if str(logs_df[col][index_no]) not in {'','-','None','NaN'}:\n",
    "            sublist = str(logs_df[col][index_no]).split()\n",
    "            sublist_len=len(sublist)\n",
    "            match_count = 0\n",
    "            for ind in (i for i,el in enumerate(raw_split) if el==sublist[0]):\n",
    "                # words in raw log not present in the parsed log will be labeled with 'O'\n",
    "                if (match_count < 1) and (raw_split[ind:ind+sublist_len]==sublist) and (label_list[ind:ind+sublist_len] == ['O'] * sublist_len):\n",
    "                    label_list[ind] = 'B-'+col\n",
    "                    label_list[ind+1:ind+sublist_len] = ['I-'+col] * (sublist_len - 1)\n",
    "                    match_count = 1\n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df['raw_preprocess'] = logs_df.raw.str.replace('\"','')\n",
    "\n",
    "# column names to use as lables\n",
    "cols = logs_df.columns.values.tolist()\n",
    "\n",
    "# do not use raw columns as labels\n",
    "cols.remove('raw')\n",
    "cols.remove('raw_preprocess')\n",
    "\n",
    "# using for loop for labeling funcition until string UDF capability in rapids- it is currently slow\n",
    "labels = []\n",
    "for indx in range(len(logs_df)):\n",
    "    labels.append(labeler(indx, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-remote_host', 'O', 'O', 'B-time_received', 'I-time_received', 'B-request_method', 'B-request_url', 'O', 'O', 'B-response_bytes_clf', 'O', 'B-request_header_user_agent', 'I-request_header_user_agent', 'I-request_header_user_agent', 'I-request_header_user_agent', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subword Labeling\n",
    "We are using the `bert-base-cased` tokenizer vocabulary. This tokenizer splits our whitespace separated words further into in dictionary sub-word pieces. The model eventually uses the label from the first piece of a word as the sole label for the word, so we do not care about the model's ability to predict individual labels for the sub-word pieces. For training, the label used for these pieces is `X`. To learn more see the [BERT paper](https://arxiv.org/abs/1810.04805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword_labeler(tokenizer, log_list, label_list):\n",
    "    \"\"\"\n",
    "    label all subword pieces in tokenized log with an 'X'\n",
    "    \"\"\"\n",
    "    subword_labels = []\n",
    "    for log, tags in zip(log_list,label_list):\n",
    "        temp_tags = []\n",
    "        words = cudf.Series(log.split())\n",
    "        subword_counts = tokenizer(words,\n",
    "               max_length=10000,\n",
    "               max_num_rows=len(words),\n",
    "              add_special_tokens=False\n",
    "              )['metadata'][:,2]\n",
    "\n",
    "        for i, tag in enumerate(tags):\n",
    "            temp_tags.append(tag)\n",
    "            temp_tags.extend('X'* subword_counts[i].item())\n",
    "        subword_labels.append(temp_tags)\n",
    "    return subword_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.7/site-packages/cudf/core/subword_tokenizer.py:189: UserWarning: When truncation is not True, the behaviour currently differs from HuggingFace as cudf always returns overflowing tokens\n",
      "  warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 300 ms, total: 1.52 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from cudf.core.subword_tokenizer import SubwordTokenizer\n",
    "tokenizer  = SubwordTokenizer(\"resources/bert-base-cased-hash.txt\",do_lower_case=False)\n",
    "subword_labels = subword_labeler(tokenizer, logs_df.raw_preprocess.to_arrow().to_pylist(), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a set list of all labels from our dataset, add `X` for wordpiece tokens we will not have tags for and `[PAD]` for logs shorter than the length of the model's embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of labels\n",
    "label_values = list(set(x for l in labels for x in l))\n",
    "\n",
    "label_values[:0] = ['[PAD]']  \n",
    "\n",
    "# Set a dict for mapping id to tag name\n",
    "label2id = {t: i for i, t in enumerate(label_values)}\n",
    "label2id.update({'X': -100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, 'O': 1, 'B-request_url': 2, 'B-time_received': 3, 'I-error_message': 4, 'B-remote_host': 5, 'B-error_level': 6, 'I-time_received': 7, 'I-request_header_user_agent': 8, 'B-response_bytes_clf': 9, 'B-request_header_referer': 10, 'B-request_header_user_agent': 11, 'B-error_message': 12, 'B-request_method': 13, 'X': -100}\n"
     ]
    }
   ],
   "source": [
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_labels = [pad(x[:256], '[PAD]', 256) for x in subword_labels]\n",
    "int_labels = [[label2id.get(l) for l in lab] for lab in padded_labels]\n",
    "label_tensor = torch.tensor(int_labels).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Datasets\n",
    "For training and validation our datasets need three features. (1) `input_ids` subword tokens as integers padded to the specific length of the model (2) `attention_mask` a binary mask that allows the model to ignore padding (3) `labels` corresponding labels for tokens as integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(logs_df.raw_preprocess,\n",
    "          max_length=256,\n",
    "          truncation=True,\n",
    "          max_num_rows = len(logs_df.raw_preprocess),\n",
    "          add_special_tokens=False,\n",
    "          return_tensors='pt'\n",
    "     )\n",
    "input_ids=output['input_ids'].type(torch.long)\n",
    "attention_masks=output['attention_mask'].type(torch.long)\n",
    "del output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, label_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch random_split to create training and validation data subsets\n",
    "dataset_size = len(input_ids)\n",
    "training_dataset, validation_dataset = random_split(dataset, (int(dataset_size*.8), int(dataset_size*.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "train_dataloader = DataLoader(dataset=training_dataset, shuffle=True, batch_size=8)\n",
    "val_dataloader = DataLoader(dataset=validation_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning pretrained BERT\n",
    "Download pretrained model from HuggingFace and move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(label2id))\n",
    "\n",
    "# model to gpu\n",
    "model.cuda()\n",
    "# use multi-gpu if available\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer and learning rate for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    #fine tune all layer parameters\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    # only fine tune classifier parameters\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 1/2 [00:14<00:14, 14.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.23484498262405396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 2/2 [00:28<00:00, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.002498794225975871\n",
      "CPU times: user 28.5 s, sys: 156 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# using 2 epochs to avoid overfitting\n",
    "\n",
    "epochs = 2\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)[0]\n",
    "        # backward pass\n",
    "        loss.sum().backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.sum().item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no dropout or batch norm during eval\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.997121\n",
      "Accuracy score: 0.998702\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "              error_level      0.900     1.000     0.947        18\n",
      "            error_message      0.895     0.944     0.919        18\n",
      "              remote_host      1.000     1.000     1.000       182\n",
      "   request_header_referer      1.000     1.000     1.000        86\n",
      "request_header_user_agent      1.000     1.000     1.000       165\n",
      "           request_method      1.000     1.000     1.000       182\n",
      "              request_url      0.995     1.000     0.997       182\n",
      "       response_bytes_clf      1.000     1.000     1.000       180\n",
      "            time_received      0.995     1.000     0.998       200\n",
      "\n",
      "                micro avg      0.995     0.999     0.997      1213\n",
      "                macro avg      0.976     0.994     0.985      1213\n",
      "             weighted avg      0.995     0.999     0.997      1213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mapping id to label\n",
    "id2label={label2id[key] : key for key in label2id.keys()}\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for step, batch in enumerate(val_dataloader):\n",
    "    input_ids, input_mask, label_ids = batch\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=None,\n",
    "        attention_mask=input_mask,)\n",
    "        \n",
    "        # For eval mode, the first result of outputs is logits\n",
    "        logits = outputs[0] \n",
    "        \n",
    "    # Get NER predicted result\n",
    "    logits = torch.argmax(F.log_softmax(logits,dim=2),dim=2)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # Get NER true result\n",
    "    label_ids = label_ids.detach().cpu().numpy()\n",
    "    \n",
    "    # Only predict the groud truth, mask=0, will not calculate\n",
    "    input_mask = input_mask.detach().cpu().numpy()\n",
    "    \n",
    "    # Compare the valuable predict result\n",
    "    for i,mask in enumerate(input_mask):\n",
    "        # ground truth \n",
    "        temp_1 = []\n",
    "        # Prediction\n",
    "        temp_2 = []\n",
    "        \n",
    "        for j, m in enumerate(mask):\n",
    "            # Mask=0 is PAD, do not compare\n",
    "            if m: # Exclude the X label\n",
    "                if id2label[label_ids[i][j]] != \"X\" and id2label[label_ids[i][j]] != \"[PAD]\": \n",
    "                    temp_1.append(id2label[label_ids[i][j]])\n",
    "                    temp_2.append(id2label[logits[i][j]])\n",
    "            else:\n",
    "                break      \n",
    "        y_true.append(temp_1)\n",
    "        y_pred.append(temp_2)\n",
    "\n",
    "print(\"f1 score: %f\"%(f1_score(y_true, y_pred)))\n",
    "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "# Get acc , recall, F1 result report\n",
    "print(classification_report(y_true, y_pred,digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model files for future parsing with cyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.config.id2label = id2label\n",
    "model.module.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.module.save_pretrained('path/to/model/directory')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
