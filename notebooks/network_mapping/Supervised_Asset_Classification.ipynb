{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset Classification (Supervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "- Bhargav Suryadevara (NVIDIA)\n",
    "- Gorkem Batmaz (NVIDIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "* Introduction\n",
    "* Dataset\n",
    "* Reading in the datasets\n",
    "* Training and inference\n",
    "* References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to predict the function of a server with Windows Event Logs using cudf, cuml and pytorch. The machines are labeled as DC, SQL, WEB, DHCP, MAIL and SAP. The dependent variable will be the type of the machine. The features are selected from Windows Event Logs which is in a tabular format. This is a first step to learn the behaviours of certain types of machines in data-centres by classifying them probabilistically. It could help to detect unusual behaviour in a data-centre. For example, some compromised computers might be acting as web/database servers but with their original tag. \n",
    "\n",
    "This work could be expanded by using different log types or different events from the machines as features to improve accuracy. Various labels can be selected to cover different types of machines or data-centres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as torch_optim\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "from cuml.preprocessing import LabelEncoder\n",
    "from cuml.preprocessing import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000 is chosen as the batch size to optimise the performance for this dataset. It can be changed depending on the data loading mechanism or the setup used. \n",
    "\n",
    "EPOCH should also be adjusted depending on convergence for a specific dataset. \n",
    "\n",
    "label_col indicates the total number of features used plus the dependent variable. Feature names are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "label_col = '19'\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the dataset into a GPU dataframe with `cudf.read_csv()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_events_on_gpu = cudf.read_csv('win_events_18_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data had many other fields. Many of them were either static or mostly blank. After filtering those, there were 18 meaningful columns left that are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"1\" : \"eventcode\",\n",
    "    \"2\" : \"keywords\",\n",
    "    \"3\" : \"privileges\",\n",
    "    \"4\" : \"message\",\n",
    "    \"5\" : \"sourcename\", \n",
    "    \"6\" : \"taskcategory\",\n",
    "    \"7\" : \"account_for_which_logon_failed_account_domain\",\n",
    "    \"8\" : \"detailed_authentication_information_authentication_package\",\n",
    "    \"9\" : \"detailed_authentication_information_key_length\",\n",
    "    \"10\" : \"detailed_authentication_information_logon_process\",\n",
    "    \"11\" : \"detailed_authentication_information_package_name_ntlm_only\",\n",
    "    \"12\" : \"logon_type\",\n",
    "    \"13\" : \"network_information_workstation_name\",\n",
    "    \"14\" : \"new_logon_security_id\",\n",
    "    \"15\" : \"impersonation_level\",\n",
    "    \"16\" : \"network_information_protocol\",\n",
    "    \"17\" : \"network_information_direction\",\n",
    "    \"18\" : \"filter_information_layer_name\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize the columns\n",
    "Categorical columns will be converted to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in win_events_on_gpu.columns:\n",
    "    win_events_on_gpu[col] = win_events_on_gpu[col].astype('str')\n",
    "    win_events_on_gpu[col] = win_events_on_gpu[col].fillna(\"NA\")\n",
    "    win_events_on_gpu[col] = LabelEncoder().fit_transform(win_events_on_gpu[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in win_events_on_gpu.columns:\n",
    "    win_events_on_gpu[col] = win_events_on_gpu[col].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation sets using cuML `train_test_split` function\n",
    "Column 19 contains the ground truth about each machine's function that the logs come from. i.e. DC, SQL, WEB, DHCP, MAIL and SAP. Hence it will be used as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, val_X, Y, val_Y = train_test_split(win_events_on_gpu, label_col, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.index = val_Y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1176</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24921</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4289</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70496</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>2108</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74882</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1045</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4373</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  2  3   4  5  6   7  8  9  10  11  12    13    14  15  16  17  18\n",
       "13136  1  0  0  14  0  4  25  5  0   0   0   3  1176    25   3   6   1   1\n",
       "24921  0  1  0  15  0  4  22  0  0   5   0   6     0  4289   0   6   1   1\n",
       "70496  0  1  0  15  0  4  22  0  0   5   0   1   932  2108   2   6   1   1\n",
       "74882  0  1  0  15  0  4  22  4  1   7   2   6  1045    36   2   6   1   1\n",
       "61138  0  1  0  15  0  4  22  0  0   5   0   1     0  4373   2   6   1   1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13136    4\n",
       "24921    0\n",
       "70496    2\n",
       "74882    0\n",
       "61138    0\n",
       "Name: 19, dtype: int16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, test_X, Y, test_Y = train_test_split(X,Y, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index = Y.index\n",
    "test_X.index = test_Y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>1328</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>7980</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28422</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>932</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50761</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>591</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3929</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1  2  3   4  5  6   7  8  9  10  11  12   13    14  15  16  17  18\n",
       "33693   0  1  0  15  0  4  22  0  0   5   0   1  932  1328   2   6   1   1\n",
       "123     0  1  0  15  0  4  22  4  1   7   3   1  932  7980   3   6   1   1\n",
       "28422  21  1  0  23  0  1  22  3  2   6   1   6  932    25   3   6   1   1\n",
       "50761   0  1  0  15  0  4  22  4  1   7   2   1  591    34   3   6   1   1\n",
       "33602   0  1  0  15  0  4  22  0  0   5   0   1    0  3929   2   6   1   1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "Name: 19, dtype: int16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Labels\n",
    "Making sure the test set contains all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "Name: 19, dtype: int16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding columns, check values in the columns\n",
    "List the unique value counts in all the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 24,\n",
       " '2': 4,\n",
       " '3': 9,\n",
       " '4': 26,\n",
       " '5': 3,\n",
       " '6': 9,\n",
       " '7': 37,\n",
       " '8': 8,\n",
       " '9': 4,\n",
       " '10': 11,\n",
       " '11': 5,\n",
       " '12': 8,\n",
       " '13': 1408,\n",
       " '14': 8990,\n",
       " '15': 5,\n",
       " '16': 8,\n",
       " '17': 4,\n",
       " '18': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_cols = {}\n",
    "for col in X.columns:\n",
    "    catergories_cnt = X[col].max()+2\n",
    "    if catergories_cnt > 1:\n",
    "        embedded_cols[col] = catergories_cnt\n",
    "embedded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[label_col] = Y\n",
    "val_X[label_col] = val_Y\n",
    "test_X[label_col] = test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding\n",
    "Feature columns will be embedded so that they can be used as categorical values. The limit can be changed depending on the accuracy of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_col_names = embedded_cols.keys()\n",
    "embedded_col_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('1', 24), ('2', 4), ('3', 9), ('4', 26), ('5', 3), ('6', 9), ('7', 37), ('8', 8), ('9', 4), ('10', 11), ('11', 5), ('12', 8), ('13', 1408), ('14', 8990), ('15', 5), ('16', 8), ('17', 4), ('18', 4)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_cols.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12),\n",
       " (4, 2),\n",
       " (9, 5),\n",
       " (26, 13),\n",
       " (3, 2),\n",
       " (9, 5),\n",
       " (37, 19),\n",
       " (8, 4),\n",
       " (4, 2),\n",
       " (11, 6),\n",
       " (5, 3),\n",
       " (8, 4),\n",
       " (1408, 100),\n",
       " (8990, 100),\n",
       " (5, 3),\n",
       " (8, 4),\n",
       " (4, 2),\n",
       " (4, 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(n_categories, min(100, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the dataframe\n",
    "We have found that the way we partition the dataframes with a 10000 batch size gives us the optimum data loading capability. It can be adjusted for different sizes of datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitioned_dfs(df, batch_size):\n",
    "    dataset_len = df.shape[0]\n",
    "    prev_chunk_offset = 0\n",
    "    partitioned_dfs = []\n",
    "    while prev_chunk_offset < dataset_len:\n",
    "        curr_chunk_offset = prev_chunk_offset + batch_size\n",
    "        chunk = df.iloc[prev_chunk_offset:curr_chunk_offset:1]\n",
    "        partitioned_dfs.append(chunk)\n",
    "        prev_chunk_offset = curr_chunk_offset\n",
    "    return partitioned_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_dfs = get_partitioned_dfs(X, batch_size)\n",
    "val_part_dfs = get_partitioned_dfs(val_X, batch_size)\n",
    "test_part_dfs = get_partitioned_dfs(test_X, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>1328</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>932</td>\n",
       "      <td>7980</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28422</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>932</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50761</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>591</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3929</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1  2  3   4  5  6   7  8  9  10  11  12   13    14  15  16  17  18  19\n",
       "33693   0  1  0  15  0  4  22  0  0   5   0   1  932  1328   2   6   1   1   2\n",
       "123     0  1  0  15  0  4  22  4  1   7   3   1  932  7980   3   6   1   1   1\n",
       "28422  21  1  0  23  0  1  22  3  2   6   1   6  932    25   3   6   1   1   0\n",
       "50761   0  1  0  15  0  4  22  4  1   7   2   1  591    34   3   6   1   1   0\n",
       "33602   0  1  0  15  0  4  22  0  0   5   0   1    0  3929   2   6   1   1   0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del win_events_on_gpu\n",
    "del X\n",
    "del val_X\n",
    "del test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU availability\n",
    "\n",
    "If there's a GPU, data is moved on to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_drop_lin(n_in, n_out, bn, p, actn):\n",
    "    \"Sequence of batchnorm (if `bn`), dropout (with `p`) and linear (`n_in`,`n_out`) layers followed by `actn`.\"\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if p != 0: layers.append(nn.Dropout(p))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bn_drop_lin function returns a sequence of batch normalization, dropout and a linear layer. This custom layer is usually used at the end of a model.\n",
    "\n",
    "n_in represents the size of the input, n_out the size of the output, bn whether we want batch norm or not, p how much dropout, and actn (optional parameter) adds an activation function at the end.\n",
    "Reference: https://github.com/fastai/fastai/blob/master/fastai/layers.py#L44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is the fast ai tabular model. More details can be found at https://github.com/fastai/fastai/blob/master/fastai/tabular/models.py#L6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "    \"Basic model for tabular data\"\n",
    "    \n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, drops, \n",
    "                 emb_drop, use_bn, is_reg, is_multi):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont = n_emb,n_cont\n",
    "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
    "        actns = [nn.ReLU(inplace=True)] * (len(sizes)-2) + [None]\n",
    "        layers = []\n",
    "        for i,(n_in,n_out,dp,act) in enumerate(zip(sizes[:-1],sizes[1:],[0.]+drops,actns)):\n",
    "            layers += bn_drop_lin(n_in, n_out, bn=use_bn and i!=0, p=dp, actn=act)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "                x = [e(x_cat[:,i]) for i,e in enumerate(model.embeds)]\n",
    "                x = torch.cat(x, 1)\n",
    "                x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont) \n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(4, 2)\n",
       "    (2): Embedding(9, 5)\n",
       "    (3): Embedding(26, 13)\n",
       "    (4): Embedding(3, 2)\n",
       "    (5): Embedding(9, 5)\n",
       "    (6): Embedding(37, 19)\n",
       "    (7): Embedding(8, 4)\n",
       "    (8): Embedding(4, 2)\n",
       "    (9): Embedding(11, 6)\n",
       "    (10): Embedding(5, 3)\n",
       "    (11): Embedding(8, 4)\n",
       "    (12): Embedding(1408, 100)\n",
       "    (13): Embedding(8990, 100)\n",
       "    (14): Embedding(5, 3)\n",
       "    (15): Embedding(8, 4)\n",
       "    (16): Embedding(4, 2)\n",
       "    (17): Embedding(4, 2)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.04, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.001, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.01, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TabularModel(embedding_sizes, 0, 6, [200,100], [0.001,0.01], emb_drop=0.04, is_reg=False,is_multi=True, use_bn=True)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam is the optimizer used in the training process; it is popular because it produces good results in various tasks. \n",
    "In its paper, computing the first and the second moment estimates and updating the parameters are summarized as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha_{t}=\\alpha \\cdot \\sqrt{1-\\beta_{2}^{t}} /\\left(1-\\beta_{1}^{t}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta_{t} \\leftarrow \\theta_{t-1}-\\alpha_{t} \\cdot m_{t} /(\\sqrt{v_{t}}+\\hat{\\epsilon})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detailson Adam can be found at https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training, evaluation and test functions\n",
    "`train_model` function uses the dataframes to \n",
    "`val_loss` can be used with a validation function\n",
    "`predict` function will be used with a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, dfs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    \n",
    "    xb_cont_tensor = torch.zeros(0, 0)\n",
    "    xb_cont_tensor.cuda()\n",
    "    \n",
    "    for df in dfs:\n",
    "        batch = df.shape[0] \n",
    "        train_set = df.drop(label_col).to_dlpack()\n",
    "        train_set = from_dlpack(train_set).long()\n",
    "        \n",
    "        output = model(train_set, xb_cont_tensor)\n",
    "        train_label = df[label_col].to_dlpack()\n",
    "        train_label = from_dlpack(train_label).long()\n",
    "        \n",
    "        loss = F.cross_entropy(output, train_label)   \n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        \n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, dfs):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    xb_cont_tensor = torch.zeros(0, 0)\n",
    "    xb_cont_tensor.cuda()\n",
    "    \n",
    "    for df in dfs:\n",
    "        current_batch_size = df.shape[0]\n",
    "        \n",
    "        val = df.drop(label_col).to_dlpack()\n",
    "        val = from_dlpack(val).long()\n",
    "        \n",
    "        out = model(val, xb_cont_tensor)\n",
    "        \n",
    "        val_label = df[label_col].to_dlpack()\n",
    "        val_label = from_dlpack(val_label).long()\n",
    "        \n",
    "        loss = F.cross_entropy(out, val_label)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        \n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == val_label).float().sum().item()\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    \n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_set):\n",
    "    xb_cont_tensor = torch.zeros(0, 0)\n",
    "    xb_cont_tensor.cuda()\n",
    "    \n",
    "    current_batch_size = test_set.shape[0]\n",
    "\n",
    "    test_set = test_set.to_dlpack()\n",
    "    test_set = from_dlpack(test_set).long()\n",
    "    \n",
    "    out = model(test_set, xb_cont_tensor)\n",
    "    pred = torch.max(out, 1)[1].view(-1).tolist()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_part_dfs)\n",
    "        print(\"training loss: \", loss)\n",
    "        val_loss(model, val_part_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_cache():\n",
    "    # release memory.\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/clx/lib/python3.7/site-packages/cudf/io/dlpack.py:74: UserWarning: WARNING: cuDF to_dlpack() produces column-major (Fortran order) output. If the output tensor needs to be row major, transpose the output of this function.\n",
      "  return libdlpack.to_dlpack(gdf_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.920477888067111\n",
      "valid loss 3.987 and accuracy 0.482\n",
      "training loss:  0.40742612743359397\n",
      "valid loss 0.962 and accuracy 0.736\n",
      "training loss:  0.3070381289730306\n",
      "valid loss 0.313 and accuracy 0.904\n",
      "training loss:  0.2548799248944872\n",
      "valid loss 0.257 and accuracy 0.913\n",
      "training loss:  0.2262556504331736\n",
      "valid loss 0.239 and accuracy 0.923\n",
      "training loss:  0.20728669966486865\n",
      "valid loss 0.219 and accuracy 0.926\n",
      "training loss:  0.19436954608826432\n",
      "valid loss 0.211 and accuracy 0.928\n",
      "training loss:  0.1863015024571765\n",
      "valid loss 0.208 and accuracy 0.928\n",
      "training loss:  0.18150964236486616\n",
      "valid loss 0.207 and accuracy 0.928\n",
      "training loss:  0.1790416669681803\n",
      "valid loss 0.203 and accuracy 0.930\n",
      "training loss:  0.17679853713509194\n",
      "valid loss 0.201 and accuracy 0.930\n",
      "training loss:  0.17636516901632823\n",
      "valid loss 0.209 and accuracy 0.930\n",
      "training loss:  0.17703226489830243\n",
      "valid loss 0.205 and accuracy 0.929\n",
      "training loss:  0.17487056169265197\n",
      "valid loss 0.215 and accuracy 0.930\n",
      "training loss:  0.1768219748488407\n",
      "valid loss 0.203 and accuracy 0.931\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=epochs, lr=0.03, wd=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_part_dfs):\n",
    "    pred_results = []\n",
    "    true_results = []\n",
    "    for df in test_part_dfs:\n",
    "        pred_results.append(predict(model, df))\n",
    "        true_results.append(df[label_col].values_host)                           \n",
    "    pred_results = np.concatenate(pred_results).astype(np.int32)\n",
    "    true_results = np.concatenate(true_results)\n",
    "    f1_score_ = f1_score(pred_results, true_results,average='micro')\n",
    "    print('micro F1 score: %s'%(f1_score_))\n",
    "    return true_results, pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro F1 score: 0.9327287493232268\n"
     ]
    }
   ],
   "source": [
    "true_results, pred_results = inference(model, test_part_dfs)\n",
    "cleanup_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"DC\",\"DHCP\",\"MAIL\",\"SAP\",\"SQL\",\"WEB\"]\n",
    "a = confusion_matrix(true_results, pred_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DC</th>\n",
       "      <th>DHCP</th>\n",
       "      <th>MAIL</th>\n",
       "      <th>SAP</th>\n",
       "      <th>SQL</th>\n",
       "      <th>WEB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>3115</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHCP</th>\n",
       "      <td>62</td>\n",
       "      <td>604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAIL</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2394</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL</th>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>617</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEB</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DC  DHCP  MAIL  SAP  SQL  WEB\n",
       "DC    3115    28    14    1   64    4\n",
       "DHCP    62   604     1    0   18    1\n",
       "MAIL     5     0  2394    4    6    0\n",
       "SAP     16     0     2  118   21    0\n",
       "SQL    168     0     5   11  617   15\n",
       "WEB     22     0     0    0   29   43"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(a, index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that some machines' function can be predicted really well, whereas some of them need more tuning or more features. This work can be improved and expanded to cover individual data-centres to create a realistic map of the network using ML by not just relying on the naming conventions. It could also help to detect more prominent scale anomalies like multiple machines, not acting per their tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "* https://github.com/fastai/fastai/blob/master/fastai/tabular/models.py#L6\n",
    "* https://jovian.ml/aakashns/04-feedforward-nn\n",
    "* https://www.kaggle.com/dienhoa/reverse-tabular-module-of-fast-ai-v1\n",
    "* https://github.com/fastai/fastai/blob/master/fastai/layers.py#L44"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
